{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cf11017-90e6-42ef-93cb-b6b676f514a3",
   "metadata": {},
   "source": [
    "# Automation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e4334e-8c76-49e0-9b6b-309fe3cbc204",
   "metadata": {},
   "source": [
    "### Pipeline Example \n",
    "\n",
    "#### Automation and Orchestration of a Supervised Tuning Pipeline.\n",
    "\n",
    "- Reuse an existing Kubeflow Pipeline for Parameter-Efficient Fine-Tuning (PEFT) for a foundation model from Google, called [PaLM 2]. \n",
    "- Advantage of reusing a pipleline means you do not have to build it from scratch, you can only specify some of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88178549-83df-4fa8-9554-a42e96558d19",
   "metadata": {
    "height": 133,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "TRAINING_DATA_URI = \"./tune_data_stack_overflow_python_qa.jsonl\" \n",
    "EVAUATION_DATA_URI = \"./tune_eval_data_stack_overflow_python_qa.jsonl\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57609a2-7fe1-4652-933b-6ea9c16fb3d9",
   "metadata": {},
   "source": [
    "- Provide the model with a version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafd1f73-9818-4e91-99e2-12bd5b02ca03",
   "metadata": {
    "height": 82,
    "tags": []
   },
   "outputs": [],
   "source": [
    "### path to the pipeline file to reuse\n",
    "### the file is provided in the workspace as well\n",
    "template_path = 'https://us-kfp.pkg.dev/ml-pipeline/\\\n",
    "large-language-model-pipelines/tune-large-model/v2.0.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de0a586-56df-4628-a6c7-b5b823b7168e",
   "metadata": {
    "height": 31,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95fea7c-e1d4-4d55-bbce-77895e3a5320",
   "metadata": {
    "height": 31,
    "tags": []
   },
   "outputs": [],
   "source": [
    "date = datetime.datetime.now().strftime(\"%H:%d:%m:%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34abb24-208c-46ad-b5dc-85a731436cb4",
   "metadata": {
    "height": 31,
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = f\"deep-learning-ai-model-{date}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86ab578-ac94-419d-813f-162251258e95",
   "metadata": {
    "tags": []
   },
   "source": [
    "- This example uses two PaLM model parameters:\n",
    "  - `TRAINING_STEPS`: Number of training steps to use when tuning the model. For extractive QA you can set it from 100-500. \n",
    "  - `EVALUATION_INTERVAL`: The interval determines how frequently a trained model is evaluated against the created *evaluation set* to assess its performance and identify issues. Default will be 20, which means after every 20 training steps, the model is evaluated on the evaluation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44a637b-6f50-478d-8a58-8e0fc3b8b8c5",
   "metadata": {
    "height": 48,
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAINING_STEPS = 200\n",
    "EVALUATION_INTERVAL = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fc52c0-cab4-4dc1-ab53-fb81970ba408",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Load the Project ID and credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bf62a0-b7b9-4fe0-b56c-2518d7a6e672",
   "metadata": {
    "height": 48,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import authenticate\n",
    "credentials, PROJECT_ID = authenticate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8044cd-cdd3-4a36-972a-e3f6596368e7",
   "metadata": {
    "height": 31,
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fc079e-5244-4421-9648-a9640b823388",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Define the arguments, the input that goes into the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8deddf9-abad-403d-9780-0a4b4ecbca41",
   "metadata": {
    "height": 184,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_arguments = {\n",
    "    \"model_display_name\": MODEL_NAME,\n",
    "    \"location\": REGION,\n",
    "    \"large_model_reference\": \"text-bison@001\",\n",
    "    \"project\": PROJECT_ID,\n",
    "    \"train_steps\": TRAINING_STEPS,\n",
    "    \"dataset_uri\": TRAINING_DATA_URI,\n",
    "    \"evaluation_interval\": EVALUATION_INTERVAL,\n",
    "    \"evaluation_data_uri\": EVAUATION_DATA_URI,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a90d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_root \"./\"\n",
    "\n",
    "job = PipelineJob(\n",
    "        ### path of the yaml file to execute\n",
    "        template_path=template_path,\n",
    "        ### name of the pipeline\n",
    "        display_name=f\"deep_learning_ai_pipeline-{date}\",\n",
    "        ### pipeline arguments (inputs)\n",
    "        parameter_values=pipeline_arguments,\n",
    "        ### region of execution\n",
    "        location=REGION,\n",
    "        ### root is where temporary files are being \n",
    "        ### stored by the execution engine\n",
    "        pipeline_root=pipeline_root,\n",
    "        ### enable_caching=True will save the outputs \n",
    "        ### of components for re-use, and will only re-run those\n",
    "        ### components for which the code or data has changed.\n",
    "        enable_caching=True,\n",
    ")\n",
    "\n",
    "### submit for execution\n",
    "job.submit()\n",
    "\n",
    "### check to see the status of the job\n",
    "job.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7facc65c-f84b-40e8-876e-b2faa2a61135",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b61034-7243-4e03-8a46-9ef89a70bdcb",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
